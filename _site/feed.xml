<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-01-07T20:01:51+05:45</updated><id>http://localhost:4000/feed.xml</id><title type="html">Data Science |</title><subtitle>blog</subtitle><author><name>Sudip Bhujel</name></author><entry><title type="html">k-Nearest Neighbors classifier, Na√Øve Bayes classifier in Data Mining</title><link href="http://localhost:4000/journal/knn-nb-classifier.html" rel="alternate" type="text/html" title="k-Nearest Neighbors classifier, Na√Øve Bayes classifier in Data Mining " /><published>2020-01-07T00:00:00+05:45</published><updated>2020-01-07T00:00:00+05:45</updated><id>http://localhost:4000/journal/knn-nb-classifier</id><content type="html" xml:base="http://localhost:4000/journal/knn-nb-classifier.html">&lt;h1 id=&quot;i-introduction&quot;&gt;I. Introduction&lt;/h1&gt;
&lt;p&gt;Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. The machine learning is classified into different categories viz. supervised machine learning, unsupervised learning, semi-supervised learning, and reinforcement machine learning. The supervised learning algorithm takes features as input, maps to a mapping function and approximates a result. The goal is to approximate the mapping function so well that when it gets new input that it can predict the output variables for that data. The supervised learning algorithm aims to find the pattern of the features to a particular result.&lt;/p&gt;

&lt;p&gt;Classification, which is the task of assigning objects to one of several predefined categories, is a pervasive problem that encompasses many diverse applications. Examples include detecting spam email messages based upon the message header and content, categorizing cells as malignant or benign based upon the results of MRI scans, and classifying galaxies based upon their shapes.&lt;/p&gt;

&lt;p&gt;The classification problems like email is spam or not, tumor is benign or malignant, etc. are binary classification as it deals with two categories in the target class. When there are more than two categories in the target class, the classification problem resides to multilabel classification and example might be like classifying cars company based on image whether it is Honda or Volkswagen or Renault.&lt;/p&gt;

&lt;p&gt;The classification algorithm k-Nearest Neighbors classifier and Na√Øve Bayes classifier are two classifiers that better suits the classification problem. The performance metrics like Confusion matrix, Accuracy, F1 score, Precision, Recall, Heatmap, etc. gives the insight of model performance.&lt;/p&gt;

&lt;h2 id=&quot;ii-algorithms&quot;&gt;II. Algorithms&lt;/h2&gt;
&lt;p&gt;The convention used in the derivation includes a collection of labeled examples 
&lt;script type=&quot;math/tex&quot;&gt;\{(x_i,yi)\}_{i=1}^N&lt;/script&gt;
, where N is the size of the collection, 
&lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt; is the D-dimensional feature vector of example 
&lt;script type=&quot;math/tex&quot;&gt;i=1, 2, ‚Ä¶, N&lt;/script&gt; , &lt;script type=&quot;math/tex&quot;&gt;y_i&lt;/script&gt; is a real-valued target and every feature 
&lt;script type=&quot;math/tex&quot;&gt;x_i^{(j)}&lt;/script&gt; 
, 
&lt;script type=&quot;math/tex&quot;&gt;j=1, 2, ‚Ä¶, D&lt;/script&gt;
, is also a real number.&lt;/p&gt;

&lt;h3 id=&quot;a-k-nearest-neighbors-classifier&quot;&gt;A. k-Nearest Neighbors Classifier&lt;/h3&gt;

&lt;p&gt;k-Nearest Neighbors (kNN) is non parametric and instance-based learning algorithm. Contrary to other learning algorithms, it keeps all training data in memory. Once new, previously unseen example comes in, the kNN algorithm finds k training examples closest to x and returns the majority label.&lt;/p&gt;

&lt;p&gt;The closeness of two examples is given by a distance function. For example, Euclidean distance is frequently used in practice. Euclidean distance between 
&lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt;
 and 
&lt;script type=&quot;math/tex&quot;&gt;x_k&lt;/script&gt;
 is given as,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;d(\boldsymbol {x_i, x_k}) = \sqrt{(x_i^{(1)}-x_k^{(1)})^2 + (x_i^{(2)}-x_k^{(2)})^2 + ... + (x_i^{(N)}-x_k^{(N)})^2} \tag1&lt;/script&gt;

&lt;p&gt;The Euclidean distance in summation of the vector is given as;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;d(\boldsymbol {x_i, x_k}) = \sqrt{\sum_{j=1}^{D}(x_i^{(j)}-x_k^{(j)})^2} \tag2&lt;/script&gt;

&lt;p&gt;Another popular choice of the distance function is the negative cosine similarity. Cosine similarity defined as,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s(\boldsymbol {x_i, x_k})=\frac{\sum_{j=1}^{D}x_i^{(j)}x_k^{(j)}}{\sqrt{\sum_{j=1}^{D}(x_i^{(j)})^2}\sqrt{\sum_{j=1}^{D}(x_k^{(j)})^2}} \tag3&lt;/script&gt;

&lt;p&gt;The Equation (3) gives a measure of similarity of the
directions of the two vectors and &lt;script type=&quot;math/tex&quot;&gt;ùë†(\boldsymbol {x_i, x_k})&lt;/script&gt; can also be denoted
as &lt;script type=&quot;math/tex&quot;&gt;cos(\boldsymbol{x_i, x_k})&lt;/script&gt;
). If the angle between two vectors is &lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; degrees,
then two vectors point to the same direction, and cosine
similarity is equal to &lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;. If the vectors are orthogonal, the cosine
similarity is &lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt;. For vectors pointing in opposite directions, the
cosine similarity is &lt;script type=&quot;math/tex&quot;&gt;‚àí1&lt;/script&gt;. If we want to use cosine similarity as a
distance metric, we need to multiply it by &lt;script type=&quot;math/tex&quot;&gt;‚àí1&lt;/script&gt;. Other popular
distance metrics include Minkowski distance, Chebychev
distance, Mahalanobis distance, and Hamming distance. The
choice of the distance metric, as well as the value for k, are the
choices the analyst makes before running the algorithm.
The k-NN classifier starts with loading the data into memory.
The value of k (number of neighbors) defines the prediction
boundaries that means how much sorted distances are taken into
account to find the mode of the k labels. The algorithm takes
votes to classify the labels among selected k-neighbors. It
returns the majority class labels leaving behind minority. The
flowchart of the k-NN classifier is;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/datamining-KNN.png&quot; alt=&quot;datamining-knn&quot; style=&quot;height: 50rem;&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;color:grey; text-align:center; font-style:italic&quot;&gt; Fig. 1.1: k-NN flowchart&lt;/p&gt;

&lt;p&gt;The selection of the hyperparameter k has a significant effect
on the classifier. In general, for the lower value of k, the
classifier may overfit on new unseen data. The value of k is
chosen such that balances bias and variance. When k is small,
we are restraining the region of a given prediction and forcing
our classifier to be ‚Äúmore blind‚Äù to the overall distribution. A
small value for K provides the most flexible fit, which will have
low bias but high variance. Graphically, our decision boundary
will be more jagged. On the other hand, a higher k averages
more voters in each prediction and hence is more resilient to
outliers. Larger values of k will have smoother decision
boundaries which means lower variance but increased bias.
The value of k is chosen such that the desired accuracy of kNN classifier is achieved. The simple method to calculate the
value of k is plotting error versus k graph and choosing the k on
which error is minimum.&lt;/p&gt;

&lt;h3 id=&quot;b-na√Øve-bayes-classifier&quot;&gt;B. Na√Øve Bayes Classifier&lt;/h3&gt;
&lt;p&gt;Bayes‚Äô Rule or Bayes‚Äô Theorem is a statistical principle for
combining prior knowledge of the classes with new evidence
gathered from data. The class-conditional probability ùëÉ(ùëã|ùëå),
and the evidence, P(X):The Bayes‚Äô Rule (also known as the
Bayes‚Äô Theorem) stipulates that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(ùëå|\boldsymbol{X}) = \frac{P(\boldsymbol{X}|ùëå) P(ùëå)}
{P(\boldsymbol{X})}
\tag4&lt;/script&gt;

&lt;p&gt;In Bayes‚Äô rule (4), it finds the probability of event ùëå, given
that the event ùëã is true. Event ùëã is also termed as evidence.
ùëÉ(ùëå) is the priori of ùëå (the prior probability, i.e. Probability of
event before evidence is seen). ùëÉ(ùëå|ùëø) is a posteriori
probability of ùëã, i.e. probability of event after evidence is seen.
A Na√Øve Bayes classifier estimates the class-conditional
probability by assuming that the attributes are conditionally
independent, given the class label ùë¶. Here, ùëÉ(ùëø) is a class
probability and ùëÉ(ùëø|ùë¶) is a conditional probability. The
conditional independence assumption can be formally stated as
follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;ùëÉ(\boldsymbol{X}|ùëå = ùë¶) = \prod_{i=1}^dùëÉ(ùëã_ùëñ|ùëå = ùë¶)\tag5&lt;/script&gt;

&lt;p&gt;Where each attribute set &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{X} = \{ùëã_1
,ùëã_2, ‚Ä¶ ,ùëã_ùëë\}&lt;/script&gt; consists of d
attributes.
The Na√Øve Bayes is also called Simple Bayes as it assumes
that features of a measurement are independent of each other
and makes equal contribution to the outcome.&lt;/p&gt;

&lt;h2 id=&quot;iii-metrics&quot;&gt;III. METRICS&lt;/h2&gt;
&lt;p&gt;The classifier model doesn‚Äôt always give the accurate result.
There are some parameters to measure how the classifier
behave with unseen data to classify like Confusion matrix,
Accuracy, F1 score, Precision, Recall, Heatmap etc. The
different evaluation metrics are used for different kinds of
problems. We build a model, get feedback from metrics, make
improvements and continue until we achieve a desirable
accuracy. Evaluation metrics explain the performance of a
model. An important aspect of evaluation metrics is their
capability to discriminate among model results.&lt;/p&gt;

&lt;h3 id=&quot;a-confusion-matrix&quot;&gt;A. Confusion Matrix&lt;/h3&gt;
&lt;p&gt;The confusion matrix is a table that summarizes how
successful the classification model is at predicting examples
belonging to various classes. One axis of the confusion matrix
is the label that the model predicted, and the other axis is the
actual label. In a binary classification problem, there are two
classes. Let‚Äôs say, the model predicts two classes: ‚Äúspam‚Äù and
‚Äúnot_spam‚Äù:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array} {|r|r|}\hline  &amp; &amp; spam (predicted) &amp; not_spam(predicted) \\ \hline &amp; spam (actual)&amp; 23 (TP) &amp; 1 (FN) \\ \hline &amp; not_spam (actual) &amp; 12 (FP) &amp; 556(TN) \\ \hline  \end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;The above confusion matrix shows that of the 24 examples
that actually were spam, the model correctly classified 23 as
spam. In this case, we say that we have 23 true positives or TP
= 23. The model incorrectly classified 1 example as not_spam.
In this case, we have 1 false negative, or FN = 1. Similarly, of
568 examples that actually were not spam, 556 were correctly
classified (556 true negatives or TN = 556), and 12 were
incorrectly classified (12 false positives, FP = 12).&lt;/p&gt;

&lt;h3 id=&quot;b-precisionrecall&quot;&gt;B. Precision/Recall&lt;/h3&gt;
&lt;p&gt;The two most frequently used metrics to assess the model are
precision and recall. Precision is the ratio of correct positive
predictions to the overall number of positive predictions:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;precision = \frac{ùëáùëÉ}{ùëáùëÉ + ùêπùëÉ}\tag6&lt;/script&gt;

&lt;p&gt;Recall is the ratio of correct predictions to the overall number
of positive examples in the datasets:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;recall = \frac{ùëáùëÉ}{TP+FN} \tag7&lt;/script&gt;

&lt;p&gt;In the case of the spam detection problem, we want to have
high precision (we want to avoid making mistakes by detecting
that a legitimate message is spam) and we are ready to tolerate
lower recall (we tolerate some spam messages in our inbox).
The goal of classifier model is to choose between a high
precision or a high recall. It‚Äôs usually impossible to have both.
The hyperparameter tuning helps to maximize precision or
recall.&lt;/p&gt;

&lt;h3 id=&quot;c-accuracy&quot;&gt;C. Accuracy&lt;/h3&gt;
&lt;p&gt;Accuracy is given by the number of correctly classified
examples divided by the total number of classified examples. In
terms of the confusion matrix, it is given by:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;accuracy = \frac{TP+TN}{TP+TN+FP+FN} \tag8&lt;/script&gt;

&lt;p&gt;Accuracy is a useful metric when errors in predicting all
classes are equally important.&lt;/p&gt;

&lt;h3 id=&quot;d-f1-score&quot;&gt;D. F1 Score&lt;/h3&gt;
&lt;p&gt;F1-Score is the harmonic mean of precision and recall values
for a classification problem. The formula for F1-Score is as
follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F1 = \frac{recall^{-1}+precision^{-1}}{2} \tag9&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F1 = 2.\frac{precision.recall}{precision + recall}&lt;/script&gt;

&lt;p&gt;The general formula for positive real Œ≤, where Œ≤ is chosen
such that recall is considered Œ≤ times as important as precision,
is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F_{\beta}=(1+{\beta}^2) \cdot \frac{precision \cdot recall}{({\beta}^2 \cdot precision)+recall} \tag11&lt;/script&gt;

&lt;p&gt;The equation (11) or &lt;script type=&quot;math/tex&quot;&gt;ùêπ_ùõΩ&lt;/script&gt; measures the effectiveness of a model with respect
to a user who attaches Œ≤ times as much importance to recall as precision.&lt;/p&gt;

&lt;h3 id=&quot;e-heat-map&quot;&gt;E. Heat Map&lt;/h3&gt;
&lt;p&gt;The heat map can be elucidated as a cross table or spreadsheet
which contains colors instead of numbers. The default color
gradient sets the lowest value in the heat map to dark blue, the
highest value to a bright red, and mid-range values to light gray,
with a corresponding transition (or gradient) between these
extremes. Heat maps are well-suited for visualizing large
amounts of multi-dimensional data and can be used to identify
clusters of rows with similar values, as these are displayed as
areas of similar color.&lt;/p&gt;

&lt;h2 id=&quot;iv-result&quot;&gt;IV. RESULT&lt;/h2&gt;
&lt;p&gt;The value of hyperparameter like k in the k-NN classifier
plays a significant role to correctly classify the labels or target
variables. The error versus k values plot provides a guideline to
choose k and the value of k with minimum error is chosen.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/k_value_vs_error.png&quot; alt=&quot;errorvsk&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;color:grey; text-align:center; font-style:italic&quot;&gt; Fig. 5.1: Error versus K-value&lt;/p&gt;

&lt;p&gt;Fig. 5. 1 shows the fluctuation of error at different values of
k and the graph is not continuous. We would rather prefer to
calculate minimum error k-value than maximum error k-value
as minimum error k-value gives more accurate prediction. The
minimum error of k-NN classifier model for test set is at ùëò =
12 and the error is 0.0467 (i.e. 4.67%). Hence, ùëò = 12 is chosen
as k-value for k-NN classifier. The performance metrics of kNN classifier with parameters metric as ‚Äòminkowski‚Äô,
neighbors as ‚Äò12‚Äôare:&lt;/p&gt;

&lt;p&gt;Confusion matrix: [[136 6] &lt;br /&gt;
$\qquad$ $\qquad$ $\qquad$ [8 150]],&lt;br /&gt;
Precision for label ‚Äò0‚Äô prediction: 0.94, &lt;br /&gt;
Precision for label ‚Äò1‚Äô prediction: 0.96, &lt;br /&gt;
Recall for label ‚Äò0‚Äô prediction: 0.96, &lt;br /&gt;
Recall for label ‚Äò1‚Äô prediction: 0.95, &lt;br /&gt;
F1-score for label ‚Äò0‚Äô prediction: 142, &lt;br /&gt;
F1-score for label ‚Äò1‚Äô prediction: 158, &lt;br /&gt;
Accuracy: 0.95 &lt;br /&gt;
The model has classified the labels with ùëáùëÉ = 136,ùêπùëÅ =
6, ùêπùëÉ = 8, ùëáùëÅ = 150 that means model misclassified 6 labels
as label ‚Äò1‚Äô which is actually label ‚Äò0‚Äô and misclassified 8 labels as label ‚Äò0‚Äô which is actually label ‚Äò1‚Äô. Hence, the model has an accuracy of about 95%.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/heat_map.jpg&quot; alt=&quot;heatmap&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;color:grey; text-align:center; font-style:italic&quot;&gt; Fig. 5.2: Heat map predicted label over the true label&lt;/p&gt;

&lt;p&gt;Fig. 5. 2 Heat map predicted label over the true label
Heat map is a graphical representation of value in the
confusion matrix obtained from the predicted label and actual
target name. In the above heatmap, the red square denotes the
maximum value on the confusion matrix and with a decrease in
value the color fades up. Diagonal elements have a higher value
as shown in the heatmap which shows a higher performance of
the classification model and informs predicated label matches
the true label for any given input.&lt;/p&gt;

&lt;p&gt;For the given model, ‚Äúprime minister of nepal‚Äù supplied as
input assign a label ‚Äútalk.politics.mideast‚Äù similarly , when
‚Äújoker‚Äù is supplied as input assign a label
‚Äúcomp.sys.ibm.pc.hardware‚Äù. Here for two different input two
different label has been assigned out of which one label
assigned for the input ‚Äúprime minister of nepal‚Äù is correct
whereas for ‚Äújoker‚Äù correct label has not been assigned
properly which is due to na√Øve base treating the input as
independent values as well as lack of data being supplied.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The two popular classifiers k-NN and Na√Øve Bayes provide
good accuracy to the model. Many parameters contribute to
model performance. The right choice of hyperparameter also
yields a better result. There is no rule of thumb to select the right
value of hyperparameter for the first trial and the
hyperparameter value that works fine for one model may not
yield the same result for another model. The good model is that
which considers all the performance metric parameters like
Accuracy, F1-score, Precision, Recall, etc. Though we have so
many metrics parameters to evaluate the model performance,
some analytics is needed to better explain the metric that
addresses classification problems in the best possible way. The
contribution of all performance metrics needs to be analyzed to
make the model accurate.&lt;/p&gt;

&lt;h2 id=&quot;appendix&quot;&gt;Appendix&lt;/h2&gt;
&lt;h3 id=&quot;a-k-nn-classifier&quot;&gt;A. k-NN classifier&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Importing the libraries&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classification_report&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy_score&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.neighbors&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KNeighborsClassifier&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StandardScaler&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Importing the dataset&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'datasets/Dataset_1.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index_col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Quick look at data&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Standardizing the variables&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StandardScaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'TARGET CLASS'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scaled_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'TARGET&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;CLASS'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_feat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaled_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# After standardization&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_feat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# train test split&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;scaled_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'TARGET CLASS'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Initializing error and k_value list&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;k_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;k_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# Using KNN&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;knn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KNeighborsClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_neighbors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;knn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;knn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;error_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Plotting k_value and error&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'K value'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Error'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;savefig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'k_value_vs_erro.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dpi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bbox_inches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tight&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;performance_report&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_neighbors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# k-NN classifier&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;knn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KNeighborsClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_neighbors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_neighbors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;knn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;knn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;confusion_matrix_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;classification_report_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classification_report&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'confusion_matrix'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'classification_report'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classification_report_&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# to numpy&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;error_np&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;k_value_np&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;error_min_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error_np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# numpy int to&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;python&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;k_value_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k_value_np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error_min_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'K= {} and error= {}'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k_value_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;error_np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k_value_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# for minimum error&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;performance_report_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;performance_report&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_neighbors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k_value_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'For k = {}: &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; {}{}'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k_value_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;performance_report_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'confusion_matrix'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;performance_report_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'classification_report'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;b-na√Øve-bayes-classifier-1&quot;&gt;B. Na√Øve Bayes classifier&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Importing the libraries&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;seaborn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;impor&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fetch_20newsgroups&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TfidfVectorizer&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.naive_bayes&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultinomialNB&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.pipeline&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_pipeline&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# importing the dataset&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fetch_20newsgroups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# training the data on these categories&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;categories&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_names&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fetch_20newsgroups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;categories&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;categories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fetch_20newsgroups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;categories&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;categories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Pipelining the model&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_pipeline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TfidfVectorizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;MultinomialNB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Fitting the data&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# heatmap&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heatmap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;square&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;annot&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'d'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cbar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yticklabels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'true label'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'predicted label'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# plt.tight_layout()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;savefig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'images/lab04/heat_map.jpg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dpi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bbox_inches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tight&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# predicting&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict_category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# prediction&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict_category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Jesus christ'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict_category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Prime minister of Nepal'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict_category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Everest'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;P. Tan, M. Steinbach, V. Kumar and A. Karpatne, Introduction to Data
Mining, Global Edition. Harlow, United Kingdom: Pearson Education
Limited, 2019.&lt;/li&gt;
  &lt;li&gt;A. Burkov, The hundred-page machine learning book, Global Edition.
Quebec City, Canada, 2019.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Sudip Bhujel</name></author><category term="datamining" /><category term="datascience" /><category term="machinelearning" /><summary type="html">I. Introduction Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. The machine learning is classified into different categories viz. supervised machine learning, unsupervised learning, semi-supervised learning, and reinforcement machine learning. The supervised learning algorithm takes features as input, maps to a mapping function and approximates a result. The goal is to approximate the mapping function so well that when it gets new input that it can predict the output variables for that data. The supervised learning algorithm aims to find the pattern of the features to a particular result.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/knnandnaivebayes.png" /></entry><entry><title type="html">Data Mining Parameters</title><link href="http://localhost:4000/journal/data-mining-parameters.html" rel="alternate" type="text/html" title="Data Mining Parameters" /><published>2019-12-28T00:00:00+05:45</published><updated>2019-12-28T00:00:00+05:45</updated><id>http://localhost:4000/journal/data-mining-parameters</id><content type="html" xml:base="http://localhost:4000/journal/data-mining-parameters.html">&lt;p&gt;Datamining covers everything that are related with the data from collection of raw data to EDA and preparation of input to AI algorithm. We have lots of parameters for describing the data. Some of them we are going to discuss are Impurity index, Central of tendency, Eigenvalue/ Eigenvector, PCA in Classification. &lt;br /&gt;
 &lt;strong&gt; Abstract: &lt;i&gt; The impurities measurement parameter of dataset
like Entropy, Gini, Classification Error aims to find the error while classifying the labels. The attribute with less value of impurity will be chosen out of attribute contenders. The measure
of central tendency like mean, median, quartiles, etc. along with boxplot gives the idea about the distribution of data and outliers which leads then how to treat the data to get the most information
out of it. The features/ attributes are important parameters for any machine learning algorithm, large-sized attributes result in a more accurate prediction which means that the model has high
accuracy. The computational cost for a model with a large number of attributes is generally high. The best model is that which takes as least attributes as possible without losing the information and has reasonable accuracy. Principal Component Analysis (PCA) is a feature extraction method that uses orthogonal linear projections to capture the underlying variance of the data. It reduces the number of least wanted features for prediction without losing the overall information of data. &lt;/i&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;entropy&quot;&gt;Entropy&lt;/h2&gt;
&lt;p&gt;Entropy is a measure of impurity, disorder or uncertainty in a bunch of examples i.e. it is an indicator of how messy our data is. In Decision Trees, the goal is to tidy the data. Entropy controls how a Decision Tree decides to split the data. It affects how a Decision Tree draws its boundaries so that the outcomes from the algorithm will have purely classified objects.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E(x) = \sum_{x\epsilon X} p(x)log_2 p(x)&lt;/script&gt;

&lt;p&gt;Where,
S = The current dataset for which entropy is being calculated &lt;br /&gt;
X = Set of classes in S&lt;br /&gt;
p(x) = The probability of each set S&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Impurity_vs_Probability.png&quot; alt=&quot;Impurity vs probability&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;color:grey; text-align:center; font-style:italic&quot;&gt; Impurity Index versus Probability, Impurity Indices are Entropy, Gini, and Classification Error&lt;/p&gt;

&lt;h2 id=&quot;gini&quot;&gt;Gini&lt;/h2&gt;
&lt;p&gt;Impurity measures such as entropy and Gini index tend to favor attributes that have a large number of distinct values . If we consider the same example as in entropy, the gini index is computed using the following equation:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;G(S) = 1-\sum_{x\epsilon X} |p(x)|^2&lt;/script&gt;

&lt;p&gt;Where,
S = The current dataset for which entropy is being calculated &lt;br /&gt;
X = Set of classes in S &lt;br /&gt;
p(x) = The probability of each set S&lt;/p&gt;

&lt;h2 id=&quot;classification-error&quot;&gt;Classification Error&lt;/h2&gt;
&lt;p&gt;Classification error is a measure of impurity at a node and defined for classification error at a node t as,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Error(t) = 1 ‚àí maxP(i|t)&lt;/script&gt;

&lt;p&gt;The classification error made by node ranges minimum 0 when all records belong to one class to maximum &lt;script type=&quot;math/tex&quot;&gt;(1 ‚àí 1/n_c )&lt;/script&gt; when records are equally distributed among all classes.&lt;/p&gt;

&lt;h2 id=&quot;covariance-matrix&quot;&gt;Covariance Matrix&lt;/h2&gt;
&lt;p&gt;Variance measures the variation of a single random variable
(like the height of a person in a population), whereas covariance
is a measure of how much two random variables vary together
(like the height of a person and the weight of a person in a
population). The covariance matrix can be calculated using
covariance, which is a square matrix given by C I,j = œÉ(x i , x j )
where C ‚àà R d xd and d describe dimension or number of
random variables of the data (e.g. the number of features like
height, width, weight, etc.). The calculation for the covariance
matrix can be also expressed as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C = \frac{1}{n-1} \sum_{i=1} ^n (X_i-\overline{X} )(X_i-\overline{X} )^T&lt;/script&gt;

&lt;p&gt;The covariance matrix for two dimensions is given by,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{pmatrix} \sigma(x,x) &amp; \sigma(x,y) \\\ \sigma(y,x) &amp; \sigma(y,y) \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;The covariance matrix is symmetric since &lt;script type=&quot;math/tex&quot;&gt;\sigma(x_i, x_j) = \sigma(x_j, x_i)&lt;/script&gt;.&lt;/p&gt;

&lt;h2 id=&quot;eigenvalue-and-eigenvector&quot;&gt;Eigenvalue and Eigenvector&lt;/h2&gt;
&lt;p&gt;In linear algebra, an eigenvector of a linear transformation is
a nonzero vector that changes at most by a scalar factor when
that linear transformation is applied to it. The corresponding
eigenvalue is the factor by which the eigenvector is scaled. For
linear equations:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Av = Œªv&lt;/script&gt;

&lt;p&gt;In this equation A is an n-by-n matrix, v is a non-zero n-by-1
vector and &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; is a scalar (which may be either real or complex).
Any value of &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; for which this equation has a solution is known
as eigenvalue of the matrix A. It is sometimes also called the
characteristics value. The vector, v, which corresponds to this
value is called an eigenvector. The eigen problem can be written
as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A. v ‚àí \lambda. v = 0 \\
A. v ‚àí \lambda. I. v = 0 \\
(A ‚àí \lambda. I). v = 0&lt;/script&gt;

&lt;p&gt;If v is non-zero, this equation will only have a solution if
&lt;script type=&quot;math/tex&quot;&gt;|A ‚àí \lambda. I| = 0&lt;/script&gt;
This equation is called the characteristic equation of A, and is
an nth order polynomial in &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; with n roots. These roots are called
the eigenvalues of A. We will only deal with the case of n
distinct roots, though they may be repeated. For each
eigenvalue, there will be an eigenvector for which the
eigenvalue equation is true.&lt;/p&gt;

&lt;h2 id=&quot;distances&quot;&gt;Distances&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Euclidean distance&lt;/strong&gt; is a measure of the distance between two
points in Euclidean space. Mathematically,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;dist = \sqrt{\sum_{k=1}^n (p_k - q_k)^2}&lt;/script&gt;

&lt;p&gt;Where n is the number of dimensions (attributes) and &lt;script type=&quot;math/tex&quot;&gt;p_k&lt;/script&gt; and
&lt;script type=&quot;math/tex&quot;&gt;q_k&lt;/script&gt; are, respectively, the &lt;script type=&quot;math/tex&quot;&gt;k^th&lt;/script&gt; attributes (components) or data
objects p and q.
&lt;strong&gt;Minkowski Distance &lt;/strong&gt; is a generalization of Euclidean
distance and given as,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;dist = \left(\sum_{k=1}^n |p_k - q_k|^r \right)^{\frac{1}{r}}&lt;/script&gt;

&lt;p&gt;Where r is a parameter, n is the number of dimensions
(attributes) and &lt;script type=&quot;math/tex&quot;&gt;p_k&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;q_k&lt;/script&gt; are, respectively, the k th attributes
(components) or data objects p and q.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;r = 1, it becomes Manhattan distance.&lt;/li&gt;
  &lt;li&gt;r = 2, it becomes Euclidean distance.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;r \to \infty&lt;/script&gt;, it becomes supremum distance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;similarity&quot;&gt;Similarity&lt;/h2&gt;
&lt;p&gt;The similarity is the measure of how much alike two data
objects are. The similarity in a data mining context is usually
described as a distance with dimensions representing features
of the objects. A small distance indicating a high degree of
similarity and a large distance indicating a low degree of
similarity. The similarity is subjective and is highly dependent
on the domain and application.&lt;br /&gt;
&lt;strong&gt;Cosine Similarity&lt;/strong&gt; of two document vectors is given as,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;cos(d_1, d_2) = \frac{d_1 . d_2}{||d_1||.||d_2||}&lt;/script&gt;

&lt;p&gt;Where ||d|| is the length of vector d.&lt;br /&gt;
Cosine similarity is for comparing two real-valued vectors,
but &lt;strong&gt;Jaccard similarity&lt;/strong&gt; is for comparing two binary vectors
(sets). Mathematically,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J_g (a,b) = frac{sum_i min(a_i, b_i)}{sum_i max(a_i, b_i)}&lt;/script&gt;

&lt;p&gt;For example, &lt;script type=&quot;math/tex&quot;&gt;t_1 = (1, 1,0,1), t_2 = (2,0,1,1)&lt;/script&gt;, the generalized
Jaccard similarity index can be computed as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(t_1, t_2) = \frac{1+0+0+1}{2+1+1+1} = 0.4&lt;/script&gt;

&lt;h2 id=&quot;pca&quot;&gt;PCA&lt;/h2&gt;
&lt;p&gt;Principal Component Analysis (PCA) is a feature extraction
method that uses orthogonal linear projections to capture the
underlying variance of the data. The main idea of principal
component analysis (PCA) is to reduce the dimensionality of a
data set consisting of many variables correlated with each other,
either heavily or lightly, while retaining the variation present in
the dataset, up to the maximum extent. It reduces the dimension
of the data with the aim of retaining as much information as
possible. In other words, this method combines highly
correlated variables to form a smaller number of an artificial set
of variables which is called ‚Äúprincipal components‚Äù that
account for the most variance in the data.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;CONCLUSION&lt;/h2&gt;
&lt;p&gt;The measure of central of tendency, similarity, etc. are the
part of Exploratory Data Analysis (EDA). The EDA itself
doesn‚Äôt give the model for prediction but extremely useful for
getting the sense of information from data. This gives an idea
about how to get started with the data. Impurity indices like
Entropy, Gini, and Classification Error in the classification
helps examine how classification algorithm struggles to classify
the items based on their attributes. The impurity index helps
find the depth of the decision tree algorithm.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/Introduction-Mining-Whats-Computer-Science/dp/0133128903/ref=sr_1_5?keywords=data+mining&amp;amp;qid=1577535801&amp;amp;sr=8-5&quot;&gt;P. Tan, M. Steinbach, V. Kumar and A. Karpatne, Introduction to Data
Mining, Global Edition. Harlow, United Kingdom: Pearson Education
Limited, 2019.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Sudip Bhujel</name></author><category term="datamining" /><category term="EDA" /><summary type="html">Datamining covers everything that are related with the data from collection of raw data to EDA and preparation of input to AI algorithm. We have lots of parameters for describing the data. Some of them we are going to discuss are Impurity index, Central of tendency, Eigenvalue/ Eigenvector, PCA in Classification. Abstract: The impurities measurement parameter of dataset like Entropy, Gini, Classification Error aims to find the error while classifying the labels. The attribute with less value of impurity will be chosen out of attribute contenders. The measure of central tendency like mean, median, quartiles, etc. along with boxplot gives the idea about the distribution of data and outliers which leads then how to treat the data to get the most information out of it. The features/ attributes are important parameters for any machine learning algorithm, large-sized attributes result in a more accurate prediction which means that the model has high accuracy. The computational cost for a model with a large number of attributes is generally high. The best model is that which takes as least attributes as possible without losing the information and has reasonable accuracy. Principal Component Analysis (PCA) is a feature extraction method that uses orthogonal linear projections to capture the underlying variance of the data. It reduces the number of least wanted features for prediction without losing the overall information of data.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/data-mining-parameters.jpeg" /></entry><entry><title type="html">Welcome to Lagrange!</title><link href="http://localhost:4000/journal/welcome-to-lagrange.html" rel="alternate" type="text/html" title="Welcome to Lagrange!" /><published>2016-01-01T00:00:00+05:45</published><updated>2016-01-01T00:00:00+05:45</updated><id>http://localhost:4000/journal/welcome-to-lagrange</id><content type="html" xml:base="http://localhost:4000/journal/welcome-to-lagrange.html">&lt;p&gt;Lagrange is a minimalist Jekyll theme. The purpose of this theme is to provide a simple, clean, content-focused blogging platform for your personal site or blog. Below you can find everything you need to get started.&lt;/p&gt;

&lt;h2 id=&quot;getting-started&quot;&gt;Getting Started&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;/journal/getting-started.html&quot;&gt;Getting Started&lt;/a&gt;: getting started with installing Lagrange, whether you are completely new to using Jekyll, or simply just migrating to a new Jekyll theme.&lt;/p&gt;

&lt;h2 id=&quot;example-content&quot;&gt;Example Content&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;/journal/text-formatting-examples.html&quot;&gt;Text and Formatting&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;questions&quot;&gt;Questions?&lt;/h2&gt;

&lt;p&gt;This theme is completely free and open source software. You may use it however you want, as it is distributed under the &lt;a href=&quot;http://choosealicense.com/licenses/mit/&quot;&gt;MIT License&lt;/a&gt;. If you are having any problems, any questions or suggestions, feel free to &lt;a href=&quot;https://twitter.com/intent/tweet?text=My%question%about%Lagrange%is:%&amp;amp;via=paululele&quot;&gt;tweet at me&lt;/a&gt;, or &lt;a href=&quot;https://github.com/lenpaul/lagrange/issues/new&quot;&gt;file a GitHub issue&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;more-jekyll&quot;&gt;More Jekyll!&lt;/h2&gt;

&lt;h3 id=&quot;millennial&quot;&gt;Millennial&lt;/h3&gt;

&lt;p&gt;Millennial is a minimalist Jekyll blog theme that I built from scratch. The purpose of this theme is to provide a simple, clean, content-focused publishing platform for a publication or blog.&lt;/p&gt;

&lt;p&gt;Feel free to check out &lt;a href=&quot;https://lenpaul.github.io/Millennial/&quot; target=&quot;_blank&quot;&gt;the demo&lt;/a&gt;, where you‚Äôll also find instructions on &lt;a href=&quot;https://lenpaul.github.io/Millennial/documentation/getting-started.html&quot;&gt;how to use install&lt;/a&gt; and use the theme.&lt;/p&gt;

&lt;h3 id=&quot;portfolio-jekyll-theme&quot;&gt;Portfolio Jekyll Theme&lt;/h3&gt;

&lt;p&gt;This is a Jekyll theme built using the &lt;a href=&quot;http://devtipsstarterkit.com/&quot;&gt;DevTips Starter Kit&lt;/a&gt; as a foundation for starting, and following closely the amazing tutorial by &lt;a href=&quot;https://www.youtube.com/watch?v=T6jKLsxbFg4&amp;amp;list=PL0CB3OvPhDA_STygmp3sDenx3UpdOMk7P&quot;&gt;Travis Neilson over at DevTips&lt;/a&gt;. The purpose of this theme is to provide a clean and simple website for your portfolio. Emphasis is placed on your projects, which are shown front and center on the home page.&lt;/p&gt;

&lt;p&gt;Everything that you will ever need to know about this Jekyll theme is included in &lt;a href=&quot;https://github.com/LeNPaul/portfolio-jekyll-theme&quot;&gt;the repository&lt;/a&gt;, which you can also find in &lt;a href=&quot;https://lenpaul.github.io/portfolio-jekyll-theme/&quot;&gt;the demo site&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;jekyll-starter-kit&quot;&gt;Jekyll Starter Kit&lt;/h3&gt;

&lt;p&gt;The Jekyll Starter Kit is a simple framework for starting your own Jekyll project using all of the best practices that I learned from building my other Jekyll themes.&lt;/p&gt;

&lt;p&gt;Feel free to check out &lt;a href=&quot;https://github.com/LeNPaul/jekyll-starter-kit&quot; target=&quot;_blank&quot;&gt;the GitHub repository&lt;/a&gt;, where you‚Äôll also find instructions on how to use install and use the theme.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'HELLO'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Paul Le</name></author><category term="documentation" /><category term="sample" /><summary type="html">Lagrange is a minimalist Jekyll theme. The purpose of this theme is to provide a simple, clean, content-focused blogging platform for your personal site or blog. Below you can find everything you need to get started.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/mountains.jpg" /></entry><entry><title type="html">Getting Started</title><link href="http://localhost:4000/journal/getting-started.html" rel="alternate" type="text/html" title="Getting Started" /><published>2015-10-10T00:00:00+05:45</published><updated>2015-10-10T00:00:00+05:45</updated><id>http://localhost:4000/journal/getting-started</id><content type="html" xml:base="http://localhost:4000/journal/getting-started.html">&lt;h1 id=&quot;lagrange&quot;&gt;Lagrange&lt;/h1&gt;

&lt;p&gt;Lagrange is a minimalist Jekyll theme for running a personal blog or site for free through &lt;a href=&quot;https://pages.github.com/&quot;&gt;Github Pages&lt;/a&gt;, or on your own server. Everything that you will ever need to know about this Jekyll theme is included in the README below, which you can also find in &lt;a href=&quot;https://lenpaul.github.io/Lagrange/&quot;&gt;the demo site&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/8409329/32631384-17107870-c56e-11e7-932f-deeb7c12e4db.png&quot; alt=&quot;alt text&quot; title=&quot;Lagrange Demo Image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;notable-features&quot;&gt;Notable features&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Compatible with GitHub Pages.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Support for Jekyll‚Äôs built-in Sass/SCSS preprocessor and data files for making customizing easier.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.google.com/analytics/&quot;&gt;Google Analytics&lt;/a&gt; support.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Commenting support powered by &lt;a href=&quot;https://disqus.com/&quot;&gt;Disqus&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Optimized for search engines.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;LaTeX support through &lt;a href=&quot;https://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;
    &lt;ol&gt;
      &lt;li&gt;&lt;a href=&quot;#what-is-jekyll&quot;&gt;What is Jekyll&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#never-used-jekyll-before&quot;&gt;Never Used Jeykll Before?&lt;/a&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#installation&quot;&gt;Installation&lt;/a&gt;
    &lt;ol&gt;
      &lt;li&gt;&lt;a href=&quot;#github-pages-installation&quot;&gt;GitHub Pages Installation&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#local-installation&quot;&gt;Local Installation&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#directory-structure&quot;&gt;Directory Structure&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#starting-from-scratch&quot;&gt;Starting From Scratch&lt;/a&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#configuration&quot;&gt;Configuration&lt;/a&gt;
    &lt;ol&gt;
      &lt;li&gt;&lt;a href=&quot;#sample-posts&quot;&gt;Sample Posts&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#site-variables&quot;&gt;Site Variables&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#adding-menu-pages&quot;&gt;Adding Menu Pages&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#posts&quot;&gt;Posts&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#layouts&quot;&gt;Layouts&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#yaml-front-block-matter&quot;&gt;YAML Front Block Matter&lt;/a&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#features&quot;&gt;Features&lt;/a&gt;
    &lt;ol&gt;
      &lt;li&gt;&lt;a href=&quot;#design-considerations&quot;&gt;Design Considerations&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#disqus&quot;&gt;Disqus&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#google-analytics&quot;&gt;Google Analytics&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#rss-feeds&quot;&gt;RSS Feeds&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#social-media-icons&quot;&gt;Social Media Icons&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mathjax&quot;&gt;MathJax&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#syntax-highlighting&quot;&gt;Syntax Highlighting&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#markdown&quot;&gt;Markdown&lt;/a&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#everything-else&quot;&gt;Everything Else&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#Contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#questions&quot;&gt;Questions?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#credits&quot;&gt;Credits&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#license&quot;&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Lagrange is a Jekyll theme that was built to be 100% compatible with &lt;a href=&quot;https://pages.github.com/&quot;&gt;GitHub Pages&lt;/a&gt;. If you are unfamiliar with GitHub Pages, you can check out &lt;a href=&quot;https://help.github.com/categories/github-pages-basics/&quot;&gt;their documentation&lt;/a&gt; for more information. &lt;a href=&quot;http://jmcglone.com/guides/github-pages/&quot;&gt;Jonathan McGlone‚Äôs guide&lt;/a&gt; on creating and hosting a personal site on GitHub is also a good resource.&lt;/p&gt;

&lt;h3 id=&quot;what-is-jekyll&quot;&gt;What is Jekyll?&lt;/h3&gt;

&lt;p&gt;Jekyll is a simple, blog-aware, static site generator for personal, project, or organization sites. Basically, Jekyll takes your page content along with template files and produces a complete website. For more information, visit the &lt;a href=&quot;https://jekyllrb.com/docs/home/&quot;&gt;official Jekyll site&lt;/a&gt; for their documentation. Codecademy also offers a great course on &lt;a href=&quot;https://www.codecademy.com/learn/deploy-a-website&quot;&gt;how to deploy a Jekyll site&lt;/a&gt; for complete beginners.&lt;/p&gt;

&lt;h3 id=&quot;never-used-jekyll-before&quot;&gt;Never Used Jekyll Before?&lt;/h3&gt;

&lt;p&gt;The beauty of hosting your website on GitHub is that you don‚Äôt have to actually have Jekyll installed on your computer. Everything can be done through the GitHub code editor, with minimal knowledge of how to use Jekyll or the command line. All you have to do is add your posts to the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory and edit the &lt;code class=&quot;highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; file to change the site settings. With some rudimentary knowledge of HTML and CSS, you can even modify the site to your liking. This can all be done through the GitHub code editor, which acts like a content management system (CMS).&lt;/p&gt;

&lt;h2 id=&quot;installation&quot;&gt;Installation&lt;/h2&gt;

&lt;h3 id=&quot;github-pages-installation&quot;&gt;GitHub Pages Installation&lt;/h3&gt;

&lt;p&gt;To start using Jekyll right away with GitHub Pages, &lt;a href=&quot;https://github.com/LeNPaul/Lagrange/fork&quot;&gt;fork the Lagrange repository on GitHub&lt;/a&gt;. From there, you can rename your repository to ‚ÄòUSERNAME.github.io‚Äô, where ‚ÄòUSERNAME‚Äô is your GitHub username, and edit the &lt;code class=&quot;highlighter-rouge&quot;&gt;settings.yml&lt;/code&gt; file in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_data&lt;/code&gt; folder to your liking. Ensure that you have a branch named &lt;code class=&quot;highlighter-rouge&quot;&gt;gh-pages&lt;/code&gt;. Your website should be ready immediately at ‚Äòhttp://USERNAME.github.io‚Äô. Note: if you are hosting several sites under the same GitHub username, then you will have to use &lt;a href=&quot;https://help.github.com/articles/user-organization-and-project-pages/&quot;&gt;Project Pages instead of User Pages&lt;/a&gt; - just change the repository name to something other than ‚Äòhttp://USERNAME.github.io‚Äô.&lt;/p&gt;

&lt;p&gt;Head over to the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory to view all the posts that are currently on the website, and to see examples of what post files generally look like. You can simply just duplicate the template post and start adding your own content.&lt;/p&gt;

&lt;h3 id=&quot;local-installation&quot;&gt;Local Installation&lt;/h3&gt;

&lt;p&gt;For a full local installation of Lagrange, &lt;a href=&quot;https://github.com/LeNPaul/Lagrange/archive/gh-pages.zip&quot;&gt;download your own copy of Lagrange&lt;/a&gt; and unzip it into it‚Äôs own directory. From there, open up your favorite command line tool, enter &lt;code class=&quot;highlighter-rouge&quot;&gt;bundle install&lt;/code&gt;, and then enter &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;. Your site should be up and running locally at &lt;a href=&quot;http://localhost:4000&quot;&gt;http://localhost:4000&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;directory-structure&quot;&gt;Directory Structure&lt;/h3&gt;

&lt;p&gt;If you are familiar with Jekyll, then the Lagrange directory structure shouldn‚Äôt be too difficult to navigate. The following some highlights of the differences you might notice between the default directory structure. More information on what these folders and files do can be found in the &lt;a href=&quot;https://jekyllrb.com/docs/structure/&quot;&gt;Jekyll documentation site&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Lagrange/
‚îú‚îÄ‚îÄ _data                      &lt;span class=&quot;c&quot;&gt;# Data files&lt;/span&gt;
|  ‚îî‚îÄ‚îÄ settings.yml            &lt;span class=&quot;c&quot;&gt;# Theme settings and custom text&lt;/span&gt;
‚îú‚îÄ‚îÄ _includes                  &lt;span class=&quot;c&quot;&gt;# Theme includes&lt;/span&gt;
‚îú‚îÄ‚îÄ _layouts                   &lt;span class=&quot;c&quot;&gt;# Theme layouts (see below for details)&lt;/span&gt;
‚îú‚îÄ‚îÄ _posts                     &lt;span class=&quot;c&quot;&gt;# Where all your posts will go&lt;/span&gt;
‚îú‚îÄ‚îÄ assets                     &lt;span class=&quot;c&quot;&gt;# Style sheets and images are found here&lt;/span&gt;
|  ‚îú‚îÄ‚îÄ css                     &lt;span class=&quot;c&quot;&gt;# Style sheets go here&lt;/span&gt;
|  |  ‚îî‚îÄ‚îÄ main.css             &lt;span class=&quot;c&quot;&gt;# Main CSS file&lt;/span&gt;
|  |  ‚îî‚îÄ‚îÄ syntax.css           &lt;span class=&quot;c&quot;&gt;# Style sheet for code syntax highlighting&lt;/span&gt;
|  ‚îî‚îÄ‚îÄ img                     &lt;span class=&quot;c&quot;&gt;# Images go here&lt;/span&gt;
‚îú‚îÄ‚îÄ menu                       &lt;span class=&quot;c&quot;&gt;# Menu pages&lt;/span&gt;
‚îú‚îÄ‚îÄ _config.yml                &lt;span class=&quot;c&quot;&gt;# Site build settings&lt;/span&gt;
‚îú‚îÄ‚îÄ Gemfile                    &lt;span class=&quot;c&quot;&gt;# Ruby Gemfile for managing Jekyll plugins&lt;/span&gt;
‚îú‚îÄ‚îÄ index.md                   &lt;span class=&quot;c&quot;&gt;# Home page&lt;/span&gt;
‚îú‚îÄ‚îÄ LICENSE.md                 &lt;span class=&quot;c&quot;&gt;# License for this theme&lt;/span&gt;
‚îú‚îÄ‚îÄ README.md                  &lt;span class=&quot;c&quot;&gt;# Includes all of the documentation for this theme&lt;/span&gt;
‚îî‚îÄ‚îÄ rss-feed.xml               &lt;span class=&quot;c&quot;&gt;# Generates RSS 2.0 file which Jekyll points to&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;starting-from-scratch&quot;&gt;Starting From Scratch&lt;/h3&gt;

&lt;p&gt;To completely start from scratch, simply delete all the files in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;assets/img&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;menu&lt;/code&gt; folder, and add your own content. You may also replace the &lt;code class=&quot;highlighter-rouge&quot;&gt;README.md&lt;/code&gt; file with your own README. Everything in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_data&lt;/code&gt; folder and &lt;code class=&quot;highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; file can be edited to suit your needs. You may also change the &lt;code class=&quot;highlighter-rouge&quot;&gt;favicon.ico&lt;/code&gt; file to your own favicon.&lt;/p&gt;

&lt;h2 id=&quot;configuration&quot;&gt;Configuration&lt;/h2&gt;

&lt;h3 id=&quot;sample-posts&quot;&gt;Sample Posts&lt;/h3&gt;

&lt;p&gt;Visit the &lt;a href=&quot;https://lenpaul.github.io/Lagrange/&quot;&gt;the demo site&lt;/a&gt; to find sample posts that show what different types of text formatting look like. You can find these posts in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; folder, which show what the best practices for setting up your own site are.&lt;/p&gt;

&lt;h3 id=&quot;site-variables&quot;&gt;Site Variables&lt;/h3&gt;

&lt;p&gt;To change site build settings, edit the &lt;code class=&quot;highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; file found in the root of your repository, which you can tweak however you like. More information on configuration settings and plugins can be found on &lt;a href=&quot;https://jekyllrb.com/docs/configuration/&quot;&gt;the Jekyll documentation site&lt;/a&gt;. This is also where you will be able to customize the title, description, and the author/owner of your site.&lt;/p&gt;

&lt;p&gt;If you are hosting your site on GitHub Pages, then committing a change to the &lt;code class=&quot;highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; file will force a rebuild of your site with Jekyll. Any changes made should be viewable soon after. If you are hosting your site locally, then you must run &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt; again for the changes to take place.&lt;/p&gt;

&lt;p&gt;In the &lt;code class=&quot;highlighter-rouge&quot;&gt;settings.yml&lt;/code&gt; file found in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_data&lt;/code&gt; folder, you will be able to customize your site settings, such as setting Disqus comments, Google Analytics, what shows up in your menu, and social media information.&lt;/p&gt;

&lt;h3 id=&quot;adding-menu-pages&quot;&gt;Adding Menu Pages&lt;/h3&gt;

&lt;p&gt;The menu pages are found in the &lt;code class=&quot;highlighter-rouge&quot;&gt;menu&lt;/code&gt; folder in the root directory, and can be added to your menu in the &lt;code class=&quot;highlighter-rouge&quot;&gt;settings.yml&lt;/code&gt; file.&lt;/p&gt;

&lt;h3 id=&quot;posts&quot;&gt;Posts&lt;/h3&gt;

&lt;p&gt;You will find example posts in your &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit any post and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;p&gt;To add new posts, simply add a file in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory that follows the convention of &lt;code class=&quot;highlighter-rouge&quot;&gt;YYYY-MM-DD-name-of-post.md&lt;/code&gt; and includes the necessary front matter. Take a look at any sample post to get an idea about how it works. If you already have a website built with Jekyll, simply copy over your posts to migrate to Lagrange.&lt;/p&gt;

&lt;h3 id=&quot;layouts&quot;&gt;Layouts&lt;/h3&gt;

&lt;p&gt;There are two main layout options that are included with Lagrange: post and page. Layouts are specified through the &lt;a href=&quot;https://jekyllrb.com/docs/frontmatter/&quot;&gt;YAML front block matter&lt;/a&gt;. Any file that contains a YAML front block matter will be processed by Jekyll. For example:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---
layout: post
title: &quot;Example Post&quot;
---
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Examples of what posts looks like can be found in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory, which includes this post you are reading right now. Posts are the basic blog post layout, which includes a header image, post content, author name, date published, social media sharing links, and related posts.&lt;/p&gt;

&lt;p&gt;Pages are essentially the post layout without any of the extra features of the posts layout. An example of what pages look like can be found at the &lt;a href=&quot;https://lenpaul.github.io/Lagrange/menu/about.html&quot;&gt;About&lt;/a&gt; and &lt;a href=&quot;https://lenpaul.github.io/Lagrange/menu/contact.html&quot;&gt;Contacts&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In addition to the two main layout options above, there are also custom layouts that have been created for the &lt;a href=&quot;https://lenpaul.github.io/Lagrange/&quot;&gt;home page&lt;/a&gt; and the &lt;a href=&quot;https://lenpaul.github.io/Lagrange/menu/writing.html&quot;&gt;archives page&lt;/a&gt;. These are simply just page layouts with some &lt;a href=&quot;https://shopify.github.io/liquid/&quot;&gt;Liquid template code&lt;/a&gt;. Check out the &lt;code class=&quot;highlighter-rouge&quot;&gt;index.html&lt;/code&gt; file in the root directory for what the code looks like.&lt;/p&gt;

&lt;h3 id=&quot;yaml-front-block-matter&quot;&gt;YAML Front Block Matter&lt;/h3&gt;

&lt;p&gt;The recommended YAML front block is:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---
layout:
title:
author:
categories:
tags: []
image:
---
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;layout&lt;/code&gt; specifies which layout to use, &lt;code class=&quot;highlighter-rouge&quot;&gt;title&lt;/code&gt; is the page or post title, &lt;code class=&quot;highlighter-rouge&quot;&gt;categories&lt;/code&gt; can be used to better organize your posts, &lt;code class=&quot;highlighter-rouge&quot;&gt;tags&lt;/code&gt; are used when generating related posts based on the topic of the post, and &lt;code class=&quot;highlighter-rouge&quot;&gt;image&lt;/code&gt; specifies which images to use. Have a look at some posts in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory to see how these variables are set.&lt;/p&gt;

&lt;h2 id=&quot;features&quot;&gt;Features&lt;/h2&gt;

&lt;h3 id=&quot;design-considerations&quot;&gt;Design Considerations&lt;/h3&gt;

&lt;p&gt;Lagrange was designed to be a minimalist theme in order for the focus to remain on your content. For example, links are signified mainly through an underline text-decoration, in order to maximize the perceived affordance of clickability (I originally just wanted to make the links a darker shade of grey).&lt;/p&gt;

&lt;h3 id=&quot;disqus&quot;&gt;Disqus&lt;/h3&gt;

&lt;p&gt;Lagrange supports comments at the end of posts through &lt;a href=&quot;https://disqus.com/&quot;&gt;Disqus&lt;/a&gt;. In order to activate Disqus commenting, set &lt;code class=&quot;highlighter-rouge&quot;&gt;disqus.comments&lt;/code&gt; to true in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_data/settings.yml&lt;/code&gt; file. If you do not have a Disqus account already, you will have to set one up, and create a profile for your website. You will be given a &lt;code class=&quot;highlighter-rouge&quot;&gt;disqus_shortname&lt;/code&gt; that will be used to generate the appropriate comments sections for your site. More information on &lt;a href=&quot;http://www.perfectlyrandom.org/2014/06/29/adding-disqus-to-your-jekyll-powered-github-pages/&quot;&gt;how to set up Disqus&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;google-analytics&quot;&gt;Google Analytics&lt;/h3&gt;

&lt;p&gt;It is possible to track your site statistics through &lt;a href=&quot;https://www.google.com/analytics/&quot;&gt;Google Analytics&lt;/a&gt;. Similar to Disqus, you will have to create an account for Google Analytics, and enter the correct Google ID for your site under &lt;code class=&quot;highlighter-rouge&quot;&gt;google-ID&lt;/code&gt; in the &lt;code class=&quot;highlighter-rouge&quot;&gt;settings.yml&lt;/code&gt; file. More information on &lt;a href=&quot;https://michaelsoolee.com/google-analytics-jekyll/&quot;&gt;how to set up Google Analytics&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;rss-feeds&quot;&gt;RSS Feeds&lt;/h3&gt;

&lt;p&gt;Atom is supported by default through &lt;a href=&quot;https://github.com/jekyll/jekyll-feed&quot;&gt;jekyll-feed&lt;/a&gt;. With jekyll-feed, you can set configuration variables such as ‚Äòtitle‚Äô, ‚Äòdescription‚Äô, and ‚Äòauthor‚Äô, in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;RSS 2.0 is also supported through &lt;a href=&quot;http://www.rssboard.org/rss-autodiscovery&quot;&gt;RSS auto-discovery&lt;/a&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;rss-feed.xml&lt;/code&gt; file (based on the template found at &lt;a href=&quot;https://github.com/snaptortoise/jekyll-rss-feeds&quot;&gt;jekyll-rss-feeds&lt;/a&gt;) that the feed path points to when using RSS 2.0 is automatically generated based on the appropriate configuration variables found in &lt;code class=&quot;highlighter-rouge&quot;&gt;_data/settings.yml&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;To use RSS 2.0, ensure the following is done:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Uncomment the last two lines in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; file.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In &lt;code class=&quot;highlighter-rouge&quot;&gt;_data/settings.yml&lt;/code&gt;, under ‚Äòsocial‚Äô, comment out the rss-square that points to &lt;code class=&quot;highlighter-rouge&quot;&gt;feed.xml&lt;/code&gt;, and uncomment the rss-square that points to &lt;code class=&quot;highlighter-rouge&quot;&gt;rss-feed.xml&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In &lt;code class=&quot;highlighter-rouge&quot;&gt;_includes/head.html&lt;/code&gt;, comment out &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;link type=&quot;application/atom+xml&quot; rel=&quot;alternate&quot; href=&quot;http://localhost:4000/feed.xml&quot; title=&quot;Data Science |&quot; /&amp;gt;&lt;/code&gt; and uncomment the line under the RSS 2.0 comment.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;social-media-icons&quot;&gt;Social Media Icons&lt;/h3&gt;

&lt;p&gt;All social media icons are courtesy of &lt;a href=&quot;http://fontawesome.io/&quot;&gt;Font Awesome&lt;/a&gt;. You can change which icons appear, as well as the account that they link to, in the &lt;code class=&quot;highlighter-rouge&quot;&gt;settings.yml&lt;/code&gt; file in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_data&lt;/code&gt; folder.&lt;/p&gt;

&lt;h3 id=&quot;mathjax&quot;&gt;MathJax&lt;/h3&gt;

&lt;p&gt;Lagrange comes out of the box with &lt;a href=&quot;https://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt;, which allows you to display mathematical equations in your posts through the use of &lt;a href=&quot;http://www.andy-roberts.net/writing/latex/mathematics_1&quot;&gt;LaTeX&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;syntax-highlighting&quot;&gt;Syntax Highlighting&lt;/h3&gt;

&lt;p&gt;Lagrange provides syntax highlighting through &lt;a href=&quot;https://help.github.com/articles/creating-and-highlighting-code-blocks/&quot;&gt;fenced code blocks&lt;/a&gt;. Syntax highlighting allows you to display source code in different colors and fonts depending on what programming language is being displayed. You can find the full list of supported programming languages &lt;a href=&quot;https://github.com/jneen/rouge/wiki/List-of-supported-languages-and-lexers&quot;&gt;here&lt;/a&gt;. Another option is to embed your code through &lt;a href=&quot;https://en.support.wordpress.com/gist/&quot;&gt;Gist&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;markdown&quot;&gt;Markdown&lt;/h3&gt;

&lt;p&gt;As always, Jekyll offers support for GitHub Flavored Markdown, which allows you to format your posts using the &lt;a href=&quot;https://guides.github.com/features/mastering-markdown/&quot;&gt;Markdown syntax&lt;/a&gt;. Examples of these text formatting features can be seen below. You can find this post in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory as well as the &lt;code class=&quot;highlighter-rouge&quot;&gt;README.md&lt;/code&gt; file.&lt;/p&gt;

&lt;h2 id=&quot;everything-else&quot;&gt;Everything Else&lt;/h2&gt;

&lt;p&gt;Check out the &lt;a href=&quot;http://jekyllrb.com/docs/home&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll‚Äôs GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;contributing&quot;&gt;Contributing&lt;/h2&gt;

&lt;p&gt;If you would like to make a feature request, or report a bug or typo in the documentation, then please &lt;a href=&quot;https://github.com/LeNPaul/Lagrange/issues/new&quot;&gt;submit a GitHub issue&lt;/a&gt;. If you would like to make a contribution, then feel free to &lt;a href=&quot;https://help.github.com/articles/about-pull-requests/&quot;&gt;submit a pull request&lt;/a&gt; - as a bonus, I will credit all contributors below! If this is your first pull request, it may be helpful to read up on the &lt;a href=&quot;https://guides.github.com/introduction/flow/&quot;&gt;GitHub Flow&lt;/a&gt; first.&lt;/p&gt;

&lt;p&gt;Lagrange has been designed as a base for users to customize and fit to their own unique needs. Please keep this in mind when requesting features and/or submitting pull requests. Some examples of changes that I would love to see are things that would make the site easier to use, or better ways of doing things. Please avoid changes that do not benefit the majority of users.&lt;/p&gt;

&lt;h2 id=&quot;questions&quot;&gt;Questions?&lt;/h2&gt;

&lt;p&gt;This theme is completely free and open source software. You may use it however you want, as it is distributed under the &lt;a href=&quot;http://choosealicense.com/licenses/mit/&quot;&gt;MIT License&lt;/a&gt;. If you are having any problems, any questions or suggestions, feel free to &lt;a href=&quot;https://twitter.com/intent/tweet?text=My%question%about%Lagrange%is:%&amp;amp;via=paululele&quot;&gt;tweet at me&lt;/a&gt;, or &lt;a href=&quot;https://github.com/lenpaul/lagrange/issues/new&quot;&gt;file a GitHub issue&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;credits&quot;&gt;Credits&lt;/h2&gt;

&lt;h3 id=&quot;creator&quot;&gt;Creator&lt;/h3&gt;

&lt;h4 id=&quot;paul-le&quot;&gt;Paul Le&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://lenpaul.com&quot;&gt;www.lenpaul.com&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://twitter.com/paululele&quot;&gt;Twitter&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/LeNPaul&quot;&gt;GitHub&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;contributors&quot;&gt;Contributors&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/nikolalukovic&quot;&gt;nikolalukovic&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/gmemstr&quot;&gt;gmemstr&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/lynn9388&quot;&gt;lynn9388&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/robqiao&quot;&gt;robqiao&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/Mauladen&quot;&gt;Mauladen&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/dhanus&quot;&gt;dhanus&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/mlewand&quot;&gt;mlewand&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/Hguimaraes&quot;&gt;Hguimaraes&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/ilhamadun&quot;&gt;ilhamadun&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/brianclemens&quot;&gt;brianclemens&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/leyhline&quot;&gt;leyhline&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/aritra24&quot;&gt;aritra24&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/DuckSoft&quot;&gt;DuckSoft&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;icons--demo-images&quot;&gt;Icons + Demo Images&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://deathtothestockphoto.com/&quot;&gt;Death to Stock&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://fontawesome.io/&quot;&gt;Font Awesome&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;other&quot;&gt;Other&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.freecodecamp.org&quot;&gt;Free Code Camp&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.khanacademy.org/&quot;&gt;Khan Academy&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;license&quot;&gt;License&lt;/h2&gt;

&lt;p&gt;Open sourced under the &lt;a href=&quot;https://github.com/LeNPaul/Lagrange/blob/gh-pages/LICENSE.md&quot;&gt;MIT license&lt;/a&gt;.&lt;/p&gt;</content><author><name>Paul Le</name></author><category term="documentation" /><category term="sample" /><summary type="html">Lagrange</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/forest.jpg" /></entry><entry><title type="html">Text Formatting Examples</title><link href="http://localhost:4000/journal/text-formatting-examples.html" rel="alternate" type="text/html" title="Text Formatting Examples" /><published>2014-01-01T00:00:00+05:45</published><updated>2014-01-01T00:00:00+05:45</updated><id>http://localhost:4000/journal/text-formatting-examples</id><content type="html" xml:base="http://localhost:4000/journal/text-formatting-examples.html">&lt;h1 id=&quot;markdown-support&quot;&gt;Markdown Support&lt;/h1&gt;

&lt;p&gt;As always, Jekyll offers support for GitHub Flavored Markdown, which allows you to format your posts using the &lt;a href=&quot;https://guides.github.com/features/mastering-markdown/&quot;&gt;Markdown syntax&lt;/a&gt;. Examples of these text formatting features can be seen below. You can find this post in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory.&lt;/p&gt;

&lt;h2 id=&quot;basic-formatting&quot;&gt;Basic Formatting&lt;/h2&gt;

&lt;p&gt;With Markdown, it is possible to emphasize words by making them &lt;em&gt;italicized&lt;/em&gt;, using &lt;em&gt;astericks&lt;/em&gt; or &lt;em&gt;underscores&lt;/em&gt;, or making them &lt;strong&gt;bold&lt;/strong&gt;, using &lt;strong&gt;double astericks&lt;/strong&gt; or &lt;strong&gt;double underscores&lt;/strong&gt;. Of course, you can combine those two formats, with both &lt;em&gt;&lt;strong&gt;bold and italicized&lt;/strong&gt;&lt;/em&gt; text, using any combination of the above syntax. You can also add a strikethrough to text using a &lt;del&gt;double tilde&lt;/del&gt;.&lt;/p&gt;

&lt;h2 id=&quot;paragraphs&quot;&gt;Paragraphs&lt;/h2&gt;

&lt;p&gt;This is what a paragraph looks like. For the purpose of demonstration, the rest of this paragraph and the next paragraph after will mean absolutely nothing. Proin eget nibh a massa vestibulum pretium. Suspendisse eu nisl a ante aliquet bibendum quis a nunc. Praesent varius interdum vehicula. Aenean risus libero, placerat at vestibulum eget, ultricies eu enim. Praesent nulla tortor, malesuada adipiscing adipiscing sollicitudin, adipiscing eget est. Praesent nulla tortor, malesuada adipiscing adipiscing sollicitudin, adipiscing eget est.&lt;/p&gt;

&lt;p&gt;Proin eget nibh a massa vestibulum pretium. Suspendisse eu nisl a ante aliquet bibendum quis a nunc. Mauris lobortis nulla et felis ullamcorper bibendum. Phasellus et hendrerit mauris. Proin eget nibh a massa vestibulum pretium. Suspendisse eu nisl a ante aliquet bibendum quis a nunc. Praesent varius interdum vehicula. Aenean risus libero, placerat at vestibulum eget, ultricies eu enim. Praesent nulla tortor, malesuada adipiscing adipiscing sollicitudin, adipiscing eget est.&lt;/p&gt;

&lt;h2 id=&quot;headings&quot;&gt;Headings&lt;/h2&gt;

&lt;p&gt;Sometimes it is useful to have different levels of headings to structure your documents. Start lines with &lt;code class=&quot;highlighter-rouge&quot;&gt;#&lt;/code&gt; to create headings. Multiple &lt;code class=&quot;highlighter-rouge&quot;&gt;##&lt;/code&gt; in a row denote smaller heading size. The following demonstrate the full range of heading sizes:&lt;/p&gt;

&lt;h1 id=&quot;heading-one-h1&quot;&gt;Heading One (h1)&lt;/h1&gt;

&lt;h2 id=&quot;heading-two-h2&quot;&gt;Heading Two (h2)&lt;/h2&gt;

&lt;h3 id=&quot;heading-three-h3&quot;&gt;Heading Three (h3)&lt;/h3&gt;

&lt;h4 id=&quot;heading-four-h4&quot;&gt;Heading Four (h4)&lt;/h4&gt;

&lt;h5 id=&quot;heading-five-h5&quot;&gt;Heading Five (h5)&lt;/h5&gt;

&lt;h6 id=&quot;heading-six-h6&quot;&gt;Heading Six (h6)&lt;/h6&gt;

&lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt;

&lt;p&gt;You can create an inline link by wrapping link text in square brackets &lt;code class=&quot;highlighter-rouge&quot;&gt;[ ]&lt;/code&gt;, and then wrapping the URL in parentheses &lt;code class=&quot;highlighter-rouge&quot;&gt;( )&lt;/code&gt;. For example, it is very easy to &lt;a href=&quot;http://google.com&quot;&gt;link to Google!&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;blockquotes&quot;&gt;Blockquotes&lt;/h2&gt;

&lt;p&gt;Blockquotes are useful for denoting quotes, or highlighting a large block of text. Single line blockquote:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This quote will change your life.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Multi line blockquote with a cite reference:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;People think focus means saying yes to the thing you‚Äôve got to focus on. But that‚Äôs not what it means at all. It means saying no to the hundred other good ideas that there are. You have to pick carefully. I‚Äôm actually as proud of the things we haven‚Äôt done as the things I have done. Innovation is saying no to 1,000 things.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;code-and-syntax-highlighting&quot;&gt;Code and Syntax Highlighting&lt;/h2&gt;

&lt;p&gt;Code blocks are part of the Markdown spec, but syntax highlighting isn‚Äôt. However, many renderers - like GitHub or most Jekyll themes - support syntax highlighting. Which languages are supported and how those language names should be written will vary from renderer to renderer. You can find the full list of supported programming languages &lt;a href=&quot;https://github.com/jneen/rouge/wiki/List-of-supported-languages-and-lexers&quot;&gt;here&lt;/a&gt;. Also, it is possible to do &lt;code class=&quot;highlighter-rouge&quot;&gt;inline code blocks&lt;/code&gt;, by wrapping the text in ` ` ` quotations.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;No language indicated, so no syntax highlighting.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-ruby highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Tom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints 'Hi, Tom' to STDOUT.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot; data-lang=&quot;js&quot;&gt;&lt;span class=&quot;c1&quot;&gt;// Example can be run directly in your JavaScript console&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Create a function that takes two arguments and returns the sum of those arguments&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;adder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;a&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;b&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;return a + b&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Call the function&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;adder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// &amp;gt; 8&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Another option is to embed your code through &lt;a href=&quot;https://en.support.wordpress.com/gist/&quot;&gt;Gist&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;images&quot;&gt;Images&lt;/h2&gt;

&lt;p&gt;To add an image, use &lt;code class=&quot;highlighter-rouge&quot;&gt;![alt text](&amp;lt;Image url&amp;gt; &quot;Image meta title&quot;)&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://noirve.com/wp-content/uploads/2013/10/DTTSP_Coffee.jpg&quot; alt=&quot;alt text&quot; title=&quot;Example&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;unordered-and-numbered-lists&quot;&gt;Unordered and Numbered Lists&lt;/h2&gt;

&lt;p&gt;You can make an unordered and nested list by preceding one or more lines of text with &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;, or &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;, and indenting sublists. The following lists show the full range of possible list formats.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;List item one
    &lt;ul&gt;
      &lt;li&gt;List item one
        &lt;ul&gt;
          &lt;li&gt;List item one&lt;/li&gt;
          &lt;li&gt;List item two&lt;/li&gt;
          &lt;li&gt;List item three&lt;/li&gt;
          &lt;li&gt;List item four&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;List item two&lt;/li&gt;
      &lt;li&gt;List item three&lt;/li&gt;
      &lt;li&gt;List item four&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;List item two&lt;/li&gt;
  &lt;li&gt;List item three&lt;/li&gt;
  &lt;li&gt;List item four&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Numbered lists are made by using numbers instead of bullet points.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;List item one
    &lt;ol&gt;
      &lt;li&gt;List item one
        &lt;ol&gt;
          &lt;li&gt;List item one&lt;/li&gt;
          &lt;li&gt;List item two&lt;/li&gt;
          &lt;li&gt;List item three&lt;/li&gt;
          &lt;li&gt;List item four&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;List item two&lt;/li&gt;
      &lt;li&gt;List item three&lt;/li&gt;
      &lt;li&gt;List item four&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;List item two&lt;/li&gt;
  &lt;li&gt;List item three&lt;/li&gt;
  &lt;li&gt;List item four&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;mathjax-example&quot;&gt;MathJax Example&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation&quot;&gt;Schr√∂dinger equation&lt;/a&gt; is a partial differential equation that describes how the quantum state of a quantum system changes with time:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;i\hbar\frac{\partial}{\partial t} \Psi(\mathbf{r},t) = \left [ \frac{-\hbar^2}{2\mu}\nabla^2 + V(\mathbf{r},t)\right ] \Psi(\mathbf{r},t)&lt;/script&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Joseph-Louis_Millennial&quot;&gt;Joseph-Louis Millennial&lt;/a&gt; was an Italian mathematician and astronomer who was responsible for the formulation of Lagrangian mechanics, which is a reformulation of Newtonian mechanics.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\mathrm{d}}{\mathrm{d}t} \left ( \frac {\partial  L}{\partial \dot{q}_j} \right ) =  \frac {\partial L}{\partial q_j}&lt;/script&gt;

&lt;h2 id=&quot;tables&quot;&gt;Tables&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Title 1&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Title 2&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Title 3&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Title 4&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;lorem&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;lorem ipsum&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;lorem ipsum dolor&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;lorem ipsum dolor sit&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lorem ipsum dolor sit&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;lorem ipsum dolor sit&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;lorem ipsum dolor sit&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;lorem ipsum dolor sit&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lorem ipsum dolor sit&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;lorem ipsum dolor sit&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;lorem ipsum dolor sit&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;lorem ipsum dolor sit&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lorem ipsum dolor sit&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;lorem ipsum dolor sit&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;lorem ipsum dolor sit&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;lorem ipsum dolor sit&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;embedding&quot;&gt;Embedding&lt;/h2&gt;

&lt;p&gt;Plenty of social media sites offer the option of embedding certain parts of their site on your own site, such as YouTube and Twitter:&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/mthtn1X4eUY&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;a class=&quot;twitter-grid&quot; data-partner=&quot;tweetdeck&quot; href=&quot;https://twitter.com/paululele/timelines/755079130027352064&quot;&gt;New Collection&lt;/a&gt; &lt;script async=&quot;&quot; src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;inline-html-elements&quot;&gt;Inline HTML elements&lt;/h2&gt;

&lt;p&gt;HTML defines a long list of available inline tags, which you can mix with Markdown if you like. A complete list of which can be found on the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTML/Element&quot;&gt;Mozilla Developer Network&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;horizontal-rule&quot;&gt;Horizontal Rule&lt;/h2&gt;

&lt;p&gt;Can be created by having three or more hyphens &lt;code class=&quot;highlighter-rouge&quot;&gt;---&lt;/code&gt;, asterisks &lt;code class=&quot;highlighter-rouge&quot;&gt;***&lt;/code&gt;, or underscores &lt;code class=&quot;highlighter-rouge&quot;&gt;___&lt;/code&gt;:&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;useful-resources&quot;&gt;Useful Resources&lt;/h2&gt;

&lt;p&gt;More information on Markdown can be found at the following links:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/adam-p/markdown-here/wiki/Markdown-Here-Cheatsheet#code&quot;&gt;Markdown Here Cheatsheet&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.unexpected-vortices.com/sw/rippledoc/quick-markdown-example.html&quot;&gt;Quick Markdown Example&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://daringfireball.net/projects/markdown/basics&quot;&gt;Markdown Basics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.github.com/gfm/&quot;&gt;GitHub Flavoured Markdown Spec&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://help.github.com/articles/basic-writing-and-formatting-syntax/#lists&quot;&gt;Basic writing and formatting syntax&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Paul Le</name></author><category term="documentation" /><category term="sample" /><summary type="html">Markdown Support</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/cards.jpg" /></entry><entry><title type="html">Learning Resources</title><link href="http://localhost:4000/journal/learning-resources.html" rel="alternate" type="text/html" title="Learning Resources" /><published>2013-10-10T00:00:00+05:45</published><updated>2013-10-10T00:00:00+05:45</updated><id>http://localhost:4000/journal/learning-resources</id><content type="html" xml:base="http://localhost:4000/journal/learning-resources.html">&lt;p&gt;The beauty of computer programming is that you do not need to formally go to school to learn how to program. You can learn almost everything that you would need to know online, and for free. The following resources are some that I have used personally, that I highly recommend, for anyone looking to learn more about computer programming.&lt;/p&gt;

&lt;h2 id=&quot;free-code-camp&quot;&gt;&lt;a href=&quot;https://www.freecodecamp.org/&quot;&gt;Free Code Camp&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;My personal favourite for learning full stack web development. They offer a great front and back end curriculum that requires you to complete a variety of projects in order to apply the knowledge that you learn during the lessons. As a bonus, at the end of the curriculum you will have a few impressive projects under your belt for your portfolio.&lt;/p&gt;

&lt;h2 id=&quot;codecademy&quot;&gt;&lt;a href=&quot;https://www.codecademy.com/&quot;&gt;Codecademy&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Not only does Codecademy have many great courses on various web development languages such as &lt;a href=&quot;https://www.codecademy.com/learn/learn-html&quot;&gt;HTML&lt;/a&gt;, &lt;a href=&quot;https://www.codecademy.com/learn/learn-css&quot;&gt;CSS&lt;/a&gt;, and &lt;a href=&quot;https://www.codecademy.com/learn/introduction-to-javascript&quot;&gt;JavaScript&lt;/a&gt;, but they even offer a course on &lt;a href=&quot;https://www.codecademy.com/learn/deploy-a-website&quot;&gt;how to deploy a Jekyll site&lt;/a&gt;. If you are completely new to Jekyll, I would recommend working through that course as a great start for learning how to deploy your Jekyll site.&lt;/p&gt;

&lt;h2 id=&quot;khan-academy&quot;&gt;&lt;a href=&quot;https://www.khanacademy.org/&quot;&gt;Khan Academy&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;A great resource not only for learning mathematics (what most people probably know Khan Academy for), but also &lt;a href=&quot;https://www.khanacademy.org/computing/computer-programming&quot;&gt;computer programming&lt;/a&gt;. What Khan Academy offers that is different from the other two above resources is that it offers courses in &lt;a href=&quot;https://www.khanacademy.org/computing/computer-science&quot;&gt;computer science related&lt;/a&gt; topics, such as &lt;a href=&quot;https://www.khanacademy.org/computing/computer-science/algorithms&quot;&gt;algorithms&lt;/a&gt; and &lt;a href=&quot;https://www.khanacademy.org/computing/computer-science/cryptography&quot;&gt;cryptography&lt;/a&gt;. This is unique in that most online resources mostly focus on the programming side of things.&lt;/p&gt;</content><author><name>Paul Le</name></author><category term="documentation" /><category term="sample" /><summary type="html">The beauty of computer programming is that you do not need to formally go to school to learn how to program. You can learn almost everything that you would need to know online, and for free. The following resources are some that I have used personally, that I highly recommend, for anyone looking to learn more about computer programming.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/spools.jpg" /></entry><entry><title type="html">About the Author</title><link href="http://localhost:4000/journal/about-the-author.html" rel="alternate" type="text/html" title="About the Author" /><published>2013-04-04T00:00:00+05:45</published><updated>2013-04-04T00:00:00+05:45</updated><id>http://localhost:4000/journal/about-the-author</id><content type="html" xml:base="http://localhost:4000/journal/about-the-author.html">&lt;p&gt;Hi there! I‚Äôm Paul. I‚Äôm a physics major turned programmer. Ever since I first learned how to program while taking a scientific computing for physics course, I have pursued programming as a passion, and as a career. Check out &lt;a href=&quot;https://www.lenpaul.com/&quot;&gt;my personal website&lt;/a&gt; for more information on my other projects (including more Jekyll themes!), as well as some of my writing.&lt;/p&gt;</content><author><name>Paul Le</name></author><category term="documentation" /><category term="sample" /><summary type="html">Hi there! I‚Äôm Paul. I‚Äôm a physics major turned programmer. Ever since I first learned how to program while taking a scientific computing for physics course, I have pursued programming as a passion, and as a career. Check out my personal website for more information on my other projects (including more Jekyll themes!), as well as some of my writing.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/cutting.jpg" /></entry></feed>