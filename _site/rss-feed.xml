<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
	<channel>
		<title>Sudip Bhujel |</title>
		<description>blog</description>
		<link></link>
		<atom:link href="/rss-feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>k-Nearest Neighbors classifier, Na√Øve Bayes classifier in Data Mining </title>
				
					<dc:creator>Sudip Bhujel</dc:creator>
				
				
					<description>&lt;h1 id=&quot;i-introduction&quot;&gt;I. Introduction&lt;/h1&gt;
&lt;p&gt;Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. The machine learning is classified into different categories viz. supervised machine learning, unsupervised learning, semi-supervised learning, and reinforcement machine learning. The supervised learning algorithm takes features as input, maps to a mapping function and approximates a result. The goal is to approximate the mapping function so well that when it gets new input that it can predict the output variables for that data. The supervised learning algorithm aims to find the pattern of the features to a particular result.&lt;/p&gt;

</description>
				
				<pubDate>Tue, 07 Jan 2020 00:00:00 +0545</pubDate>
				<link>http://localhost:4000/journal/knn-nb-classifier.html</link>
				<guid isPermaLink="true">http://localhost:4000/journal/knn-nb-classifier.html</guid>
			</item>
		
			<item>
				<title>Data Mining Parameters</title>
				
					<dc:creator>Sudip Bhujel</dc:creator>
				
				
					<description>&lt;p&gt;Datamining covers everything that are related with the data from collection of raw data to EDA and preparation of input to AI algorithm. We have lots of parameters for describing the data. Some of them we are going to discuss are Impurity index, Central of tendency, Eigenvalue/ Eigenvector, PCA in Classification. &lt;br /&gt;
 &lt;strong&gt; Abstract: &lt;i&gt; The impurities measurement parameter of dataset
like Entropy, Gini, Classification Error aims to find the error while classifying the labels. The attribute with less value of impurity will be chosen out of attribute contenders. The measure
of central tendency like mean, median, quartiles, etc. along with boxplot gives the idea about the distribution of data and outliers which leads then how to treat the data to get the most information
out of it. The features/ attributes are important parameters for any machine learning algorithm, large-sized attributes result in a more accurate prediction which means that the model has high
accuracy. The computational cost for a model with a large number of attributes is generally high. The best model is that which takes as least attributes as possible without losing the information and has reasonable accuracy. Principal Component Analysis (PCA) is a feature extraction method that uses orthogonal linear projections to capture the underlying variance of the data. It reduces the number of least wanted features for prediction without losing the overall information of data. &lt;/i&gt;&lt;/strong&gt;&lt;/p&gt;

</description>
				
				<pubDate>Sat, 28 Dec 2019 00:00:00 +0545</pubDate>
				<link>http://localhost:4000/journal/data-mining-parameters.html</link>
				<guid isPermaLink="true">http://localhost:4000/journal/data-mining-parameters.html</guid>
			</item>
		
	</channel>
</rss>
